{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38121210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from surprise import Dataset, Reader, SVD, dump\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2108df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup paths ---\n",
    "current_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "file_path = os.path.join(current_dir, 'data', 'processed', 'hotelrec_2013_2017_cleaned_encoded.csv.gz')\n",
    "cluster_path = os.path.join(current_dir, 'data', 'processed', 'hotel_clusters.csv')\n",
    "model_save_path = os.path.join(current_dir, 'models')\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e20c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load hotel clusters ---\n",
    "hotel_clusters = pd.read_csv(cluster_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Chunk 1...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.208140\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.55034\n",
      "[100]\tvalid_0's l2: 0.539952\n",
      "[150]\tvalid_0's l2: 0.536647\n",
      "[200]\tvalid_0's l2: 0.535035\n",
      "[250]\tvalid_0's l2: 0.534251\n",
      "[300]\tvalid_0's l2: 0.534021\n",
      "[350]\tvalid_0's l2: 0.533707\n",
      "[400]\tvalid_0's l2: 0.533453\n",
      "[450]\tvalid_0's l2: 0.533295\n",
      "Early stopping, best iteration is:\n",
      "[459]\tvalid_0's l2: 0.533213\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.208140\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.309445\n",
      "[100]\tvalid_0's l2: 0.293023\n",
      "[150]\tvalid_0's l2: 0.290423\n",
      "[200]\tvalid_0's l2: 0.289261\n",
      "[250]\tvalid_0's l2: 0.288619\n",
      "[300]\tvalid_0's l2: 0.288251\n",
      "[350]\tvalid_0's l2: 0.287917\n",
      "[400]\tvalid_0's l2: 0.287626\n",
      "[450]\tvalid_0's l2: 0.287322\n",
      "[500]\tvalid_0's l2: 0.287176\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.287172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40535.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 done.\n",
      "\n",
      "Processing Chunk 2...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.158680\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.583786\n",
      "[100]\tvalid_0's l2: 0.573056\n",
      "[150]\tvalid_0's l2: 0.570345\n",
      "[200]\tvalid_0's l2: 0.569462\n",
      "[250]\tvalid_0's l2: 0.568887\n",
      "[300]\tvalid_0's l2: 0.568518\n",
      "[350]\tvalid_0's l2: 0.568354\n",
      "[400]\tvalid_0's l2: 0.568158\n",
      "Early stopping, best iteration is:\n",
      "[416]\tvalid_0's l2: 0.568113\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.158680\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.316139\n",
      "[100]\tvalid_0's l2: 0.297777\n",
      "[150]\tvalid_0's l2: 0.294555\n",
      "[200]\tvalid_0's l2: 0.293401\n",
      "[250]\tvalid_0's l2: 0.292759\n",
      "[300]\tvalid_0's l2: 0.292344\n",
      "[350]\tvalid_0's l2: 0.29201\n",
      "[400]\tvalid_0's l2: 0.291785\n",
      "[450]\tvalid_0's l2: 0.29164\n",
      "[500]\tvalid_0's l2: 0.291519\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.291519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38982.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2 done.\n",
      "\n",
      "Processing Chunk 3...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.148167\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.578446\n",
      "[100]\tvalid_0's l2: 0.566602\n",
      "[150]\tvalid_0's l2: 0.564088\n",
      "[200]\tvalid_0's l2: 0.563158\n",
      "[250]\tvalid_0's l2: 0.562689\n",
      "[300]\tvalid_0's l2: 0.562353\n",
      "[350]\tvalid_0's l2: 0.562195\n",
      "Early stopping, best iteration is:\n",
      "[362]\tvalid_0's l2: 0.562117\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.148167\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.312417\n",
      "[100]\tvalid_0's l2: 0.294581\n",
      "[150]\tvalid_0's l2: 0.291504\n",
      "[200]\tvalid_0's l2: 0.290444\n",
      "[250]\tvalid_0's l2: 0.289885\n",
      "[300]\tvalid_0's l2: 0.289536\n",
      "[350]\tvalid_0's l2: 0.289198\n",
      "[400]\tvalid_0's l2: 0.288958\n",
      "[450]\tvalid_0's l2: 0.288767\n",
      "[500]\tvalid_0's l2: 0.288518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.288518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38527.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 done.\n",
      "\n",
      "Processing Chunk 4...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.155455\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.583172\n",
      "[100]\tvalid_0's l2: 0.571218\n",
      "[150]\tvalid_0's l2: 0.568401\n",
      "[200]\tvalid_0's l2: 0.56732\n",
      "[250]\tvalid_0's l2: 0.566806\n",
      "[300]\tvalid_0's l2: 0.566573\n",
      "[350]\tvalid_0's l2: 0.566417\n",
      "[400]\tvalid_0's l2: 0.566312\n",
      "[450]\tvalid_0's l2: 0.566208\n",
      "Early stopping, best iteration is:\n",
      "[451]\tvalid_0's l2: 0.566207\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.155455\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.311138\n",
      "[100]\tvalid_0's l2: 0.292223\n",
      "[150]\tvalid_0's l2: 0.289246\n",
      "[200]\tvalid_0's l2: 0.288175\n",
      "[250]\tvalid_0's l2: 0.287497\n",
      "[300]\tvalid_0's l2: 0.287134\n",
      "[350]\tvalid_0's l2: 0.286882\n",
      "[400]\tvalid_0's l2: 0.2867\n",
      "[450]\tvalid_0's l2: 0.286522\n",
      "[500]\tvalid_0's l2: 0.286405\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's l2: 0.286404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 37861.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4 done.\n",
      "\n",
      "Processing Chunk 5...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.132313\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.587475\n",
      "[100]\tvalid_0's l2: 0.576576\n",
      "[150]\tvalid_0's l2: 0.573747\n",
      "[200]\tvalid_0's l2: 0.572841\n",
      "[250]\tvalid_0's l2: 0.5723\n",
      "[300]\tvalid_0's l2: 0.571919\n",
      "[350]\tvalid_0's l2: 0.571614\n",
      "[400]\tvalid_0's l2: 0.571462\n",
      "Early stopping, best iteration is:\n",
      "[429]\tvalid_0's l2: 0.571369\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.132313\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.316043\n",
      "[100]\tvalid_0's l2: 0.298314\n",
      "[150]\tvalid_0's l2: 0.295241\n",
      "[200]\tvalid_0's l2: 0.294284\n",
      "[250]\tvalid_0's l2: 0.293766\n",
      "[300]\tvalid_0's l2: 0.293511\n",
      "[350]\tvalid_0's l2: 0.293132\n",
      "[400]\tvalid_0's l2: 0.292933\n",
      "[450]\tvalid_0's l2: 0.292808\n",
      "[500]\tvalid_0's l2: 0.292671\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.292671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 37553.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 5 done.\n",
      "\n",
      "Processing Chunk 6...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.062910\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.618201\n",
      "[100]\tvalid_0's l2: 0.605385\n",
      "[150]\tvalid_0's l2: 0.602338\n",
      "[200]\tvalid_0's l2: 0.60133\n",
      "[250]\tvalid_0's l2: 0.600755\n",
      "[300]\tvalid_0's l2: 0.600387\n",
      "[350]\tvalid_0's l2: 0.600019\n",
      "[400]\tvalid_0's l2: 0.599849\n",
      "[450]\tvalid_0's l2: 0.599692\n",
      "[500]\tvalid_0's l2: 0.599552\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[493]\tvalid_0's l2: 0.599531\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.062910\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.323352\n",
      "[100]\tvalid_0's l2: 0.305659\n",
      "[150]\tvalid_0's l2: 0.302798\n",
      "[200]\tvalid_0's l2: 0.301822\n",
      "[250]\tvalid_0's l2: 0.301259\n",
      "[300]\tvalid_0's l2: 0.300878\n",
      "[350]\tvalid_0's l2: 0.300648\n",
      "[400]\tvalid_0's l2: 0.300479\n",
      "[450]\tvalid_0's l2: 0.300407\n",
      "[500]\tvalid_0's l2: 0.300208\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.300208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 37878.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 6 done.\n",
      "\n",
      "Processing Chunk 7...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.255133\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.529644\n",
      "[100]\tvalid_0's l2: 0.513262\n",
      "[150]\tvalid_0's l2: 0.508237\n",
      "[200]\tvalid_0's l2: 0.506205\n",
      "[250]\tvalid_0's l2: 0.505196\n",
      "[300]\tvalid_0's l2: 0.504621\n",
      "[350]\tvalid_0's l2: 0.503993\n",
      "[400]\tvalid_0's l2: 0.503638\n",
      "[450]\tvalid_0's l2: 0.503369\n",
      "[500]\tvalid_0's l2: 0.503079\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.503079\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.255133\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.302412\n",
      "[100]\tvalid_0's l2: 0.286207\n",
      "[150]\tvalid_0's l2: 0.283331\n",
      "[200]\tvalid_0's l2: 0.282255\n",
      "[250]\tvalid_0's l2: 0.281587\n",
      "[300]\tvalid_0's l2: 0.281139\n",
      "[350]\tvalid_0's l2: 0.280746\n",
      "[400]\tvalid_0's l2: 0.280546\n",
      "[450]\tvalid_0's l2: 0.280334\n",
      "[500]\tvalid_0's l2: 0.280164\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.280162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38828.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 7 done.\n",
      "\n",
      "Processing Chunk 8...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 759\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.197578\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.546519\n",
      "[100]\tvalid_0's l2: 0.525263\n",
      "[150]\tvalid_0's l2: 0.516779\n",
      "[200]\tvalid_0's l2: 0.513798\n",
      "[250]\tvalid_0's l2: 0.512162\n",
      "[300]\tvalid_0's l2: 0.510874\n",
      "[350]\tvalid_0's l2: 0.509894\n",
      "[400]\tvalid_0's l2: 0.509512\n",
      "[450]\tvalid_0's l2: 0.509038\n",
      "[500]\tvalid_0's l2: 0.508819\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.508819\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 806\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.197578\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.310182\n",
      "[100]\tvalid_0's l2: 0.293926\n",
      "[150]\tvalid_0's l2: 0.290485\n",
      "[200]\tvalid_0's l2: 0.288992\n",
      "[250]\tvalid_0's l2: 0.288198\n",
      "[300]\tvalid_0's l2: 0.287722\n",
      "[350]\tvalid_0's l2: 0.287259\n",
      "[400]\tvalid_0's l2: 0.287052\n",
      "[450]\tvalid_0's l2: 0.286781\n",
      "[500]\tvalid_0's l2: 0.286488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.286488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39088.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8 done.\n",
      "\n",
      "Processing Chunk 9...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.254105\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.517427\n",
      "[100]\tvalid_0's l2: 0.496185\n",
      "[150]\tvalid_0's l2: 0.489237\n",
      "[200]\tvalid_0's l2: 0.485373\n",
      "[250]\tvalid_0's l2: 0.483569\n",
      "[300]\tvalid_0's l2: 0.482565\n",
      "[350]\tvalid_0's l2: 0.482035\n",
      "[400]\tvalid_0's l2: 0.481487\n",
      "[450]\tvalid_0's l2: 0.481187\n",
      "[500]\tvalid_0's l2: 0.480867\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.480864\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 792\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.254105\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.312078\n",
      "[100]\tvalid_0's l2: 0.295273\n",
      "[150]\tvalid_0's l2: 0.291455\n",
      "[200]\tvalid_0's l2: 0.289681\n",
      "[250]\tvalid_0's l2: 0.288882\n",
      "[300]\tvalid_0's l2: 0.288159\n",
      "[350]\tvalid_0's l2: 0.287658\n",
      "[400]\tvalid_0's l2: 0.287272\n",
      "[450]\tvalid_0's l2: 0.28708\n",
      "[500]\tvalid_0's l2: 0.286905\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.286905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39501.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 9 done.\n",
      "\n",
      "Processing Chunk 10...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.189203\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.551573\n",
      "[100]\tvalid_0's l2: 0.536028\n",
      "[150]\tvalid_0's l2: 0.530209\n",
      "[200]\tvalid_0's l2: 0.527808\n",
      "[250]\tvalid_0's l2: 0.526328\n",
      "[300]\tvalid_0's l2: 0.525562\n",
      "[350]\tvalid_0's l2: 0.525091\n",
      "[400]\tvalid_0's l2: 0.524786\n",
      "[450]\tvalid_0's l2: 0.524537\n",
      "[500]\tvalid_0's l2: 0.524463\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.524461\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 809\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.189203\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.320549\n",
      "[100]\tvalid_0's l2: 0.303509\n",
      "[150]\tvalid_0's l2: 0.300504\n",
      "[200]\tvalid_0's l2: 0.29925\n",
      "[250]\tvalid_0's l2: 0.298346\n",
      "[300]\tvalid_0's l2: 0.297775\n",
      "[350]\tvalid_0's l2: 0.297381\n",
      "[400]\tvalid_0's l2: 0.296888\n",
      "[450]\tvalid_0's l2: 0.296638\n",
      "[500]\tvalid_0's l2: 0.296466\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.296466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39571.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 10 done.\n",
      "\n",
      "Processing Chunk 11...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.224188\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.541172\n",
      "[100]\tvalid_0's l2: 0.528928\n",
      "[150]\tvalid_0's l2: 0.524947\n",
      "[200]\tvalid_0's l2: 0.523043\n",
      "[250]\tvalid_0's l2: 0.521934\n",
      "[300]\tvalid_0's l2: 0.521325\n",
      "[350]\tvalid_0's l2: 0.520941\n",
      "[400]\tvalid_0's l2: 0.520535\n",
      "[450]\tvalid_0's l2: 0.520378\n",
      "[500]\tvalid_0's l2: 0.520232\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's l2: 0.520226\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.224188\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.307452\n",
      "[100]\tvalid_0's l2: 0.290575\n",
      "[150]\tvalid_0's l2: 0.287197\n",
      "[200]\tvalid_0's l2: 0.286035\n",
      "[250]\tvalid_0's l2: 0.285308\n",
      "[300]\tvalid_0's l2: 0.284884\n",
      "[350]\tvalid_0's l2: 0.284662\n",
      "[400]\tvalid_0's l2: 0.284462\n",
      "[450]\tvalid_0's l2: 0.284247\n",
      "[500]\tvalid_0's l2: 0.284093\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.284093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 37564.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 11 done.\n",
      "\n",
      "Processing Chunk 12...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.201778\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.549491\n",
      "[100]\tvalid_0's l2: 0.535029\n",
      "[150]\tvalid_0's l2: 0.530104\n",
      "[200]\tvalid_0's l2: 0.527947\n",
      "[250]\tvalid_0's l2: 0.526841\n",
      "[300]\tvalid_0's l2: 0.526182\n",
      "[350]\tvalid_0's l2: 0.525774\n",
      "[400]\tvalid_0's l2: 0.525338\n",
      "[450]\tvalid_0's l2: 0.525147\n",
      "[500]\tvalid_0's l2: 0.524921\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.524921\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.201778\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.307512\n",
      "[100]\tvalid_0's l2: 0.29018\n",
      "[150]\tvalid_0's l2: 0.287145\n",
      "[200]\tvalid_0's l2: 0.285808\n",
      "[250]\tvalid_0's l2: 0.285031\n",
      "[300]\tvalid_0's l2: 0.284527\n",
      "[350]\tvalid_0's l2: 0.284105\n",
      "[400]\tvalid_0's l2: 0.283736\n",
      "[450]\tvalid_0's l2: 0.283421\n",
      "[500]\tvalid_0's l2: 0.283249\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.283249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39469.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 12 done.\n",
      "\n",
      "Processing Chunk 13...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.156355\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.584082\n",
      "[100]\tvalid_0's l2: 0.57461\n",
      "[150]\tvalid_0's l2: 0.572447\n",
      "[200]\tvalid_0's l2: 0.571639\n",
      "[250]\tvalid_0's l2: 0.571255\n",
      "[300]\tvalid_0's l2: 0.571036\n",
      "[350]\tvalid_0's l2: 0.57082\n",
      "[400]\tvalid_0's l2: 0.570734\n",
      "[450]\tvalid_0's l2: 0.570641\n",
      "Early stopping, best iteration is:\n",
      "[446]\tvalid_0's l2: 0.570633\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.156355\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.323844\n",
      "[100]\tvalid_0's l2: 0.305327\n",
      "[150]\tvalid_0's l2: 0.302434\n",
      "[200]\tvalid_0's l2: 0.301253\n",
      "[250]\tvalid_0's l2: 0.300576\n",
      "[300]\tvalid_0's l2: 0.300226\n",
      "[350]\tvalid_0's l2: 0.299916\n",
      "[400]\tvalid_0's l2: 0.299797\n",
      "[450]\tvalid_0's l2: 0.299605\n",
      "[500]\tvalid_0's l2: 0.299466\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.299466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39674.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 13 done.\n",
      "\n",
      "Processing Chunk 14...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.145535\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.58893\n",
      "[100]\tvalid_0's l2: 0.58007\n",
      "[150]\tvalid_0's l2: 0.578579\n",
      "[200]\tvalid_0's l2: 0.578168\n",
      "[250]\tvalid_0's l2: 0.577804\n",
      "[300]\tvalid_0's l2: 0.577527\n",
      "[350]\tvalid_0's l2: 0.577425\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's l2: 0.577391\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.145535\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.325894\n",
      "[100]\tvalid_0's l2: 0.306789\n",
      "[150]\tvalid_0's l2: 0.303597\n",
      "[200]\tvalid_0's l2: 0.302603\n",
      "[250]\tvalid_0's l2: 0.301991\n",
      "[300]\tvalid_0's l2: 0.301594\n",
      "[350]\tvalid_0's l2: 0.301373\n",
      "[400]\tvalid_0's l2: 0.301209\n",
      "[450]\tvalid_0's l2: 0.301094\n",
      "[500]\tvalid_0's l2: 0.300955\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.300955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39597.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 14 done.\n",
      "\n",
      "Processing Chunk 15...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.203525\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.567013\n",
      "[100]\tvalid_0's l2: 0.555959\n",
      "[150]\tvalid_0's l2: 0.552513\n",
      "[200]\tvalid_0's l2: 0.551004\n",
      "[250]\tvalid_0's l2: 0.550187\n",
      "[300]\tvalid_0's l2: 0.549658\n",
      "[350]\tvalid_0's l2: 0.549316\n",
      "[400]\tvalid_0's l2: 0.549153\n",
      "[450]\tvalid_0's l2: 0.549105\n",
      "[500]\tvalid_0's l2: 0.548939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.548939\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.203525\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.31565\n",
      "[100]\tvalid_0's l2: 0.298224\n",
      "[150]\tvalid_0's l2: 0.295186\n",
      "[200]\tvalid_0's l2: 0.294192\n",
      "[250]\tvalid_0's l2: 0.293599\n",
      "[300]\tvalid_0's l2: 0.29326\n",
      "[350]\tvalid_0's l2: 0.292974\n",
      "[400]\tvalid_0's l2: 0.292785\n",
      "[450]\tvalid_0's l2: 0.292644\n",
      "[500]\tvalid_0's l2: 0.292503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.292503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 37905.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 15 done.\n",
      "\n",
      "Processing Chunk 16...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.191915\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.563209\n",
      "[100]\tvalid_0's l2: 0.552815\n",
      "[150]\tvalid_0's l2: 0.548782\n",
      "[200]\tvalid_0's l2: 0.547218\n",
      "[250]\tvalid_0's l2: 0.546462\n",
      "[300]\tvalid_0's l2: 0.546039\n",
      "[350]\tvalid_0's l2: 0.545542\n",
      "[400]\tvalid_0's l2: 0.545219\n",
      "[450]\tvalid_0's l2: 0.545061\n",
      "[500]\tvalid_0's l2: 0.544943\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[492]\tvalid_0's l2: 0.54492\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.191915\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.310604\n",
      "[100]\tvalid_0's l2: 0.293552\n",
      "[150]\tvalid_0's l2: 0.290552\n",
      "[200]\tvalid_0's l2: 0.289365\n",
      "[250]\tvalid_0's l2: 0.288702\n",
      "[300]\tvalid_0's l2: 0.288364\n",
      "[350]\tvalid_0's l2: 0.288076\n",
      "[400]\tvalid_0's l2: 0.287878\n",
      "[450]\tvalid_0's l2: 0.287649\n",
      "[500]\tvalid_0's l2: 0.287499\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.287499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39570.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 16 done.\n",
      "\n",
      "Processing Chunk 17...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.144127\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.594237\n",
      "[100]\tvalid_0's l2: 0.585586\n",
      "[150]\tvalid_0's l2: 0.583395\n",
      "[200]\tvalid_0's l2: 0.582691\n",
      "[250]\tvalid_0's l2: 0.582298\n",
      "[300]\tvalid_0's l2: 0.582116\n",
      "[350]\tvalid_0's l2: 0.582021\n",
      "Early stopping, best iteration is:\n",
      "[351]\tvalid_0's l2: 0.582014\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.144127\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.326368\n",
      "[100]\tvalid_0's l2: 0.306785\n",
      "[150]\tvalid_0's l2: 0.303533\n",
      "[200]\tvalid_0's l2: 0.302517\n",
      "[250]\tvalid_0's l2: 0.301955\n",
      "[300]\tvalid_0's l2: 0.301563\n",
      "[350]\tvalid_0's l2: 0.301345\n",
      "[400]\tvalid_0's l2: 0.301157\n",
      "[450]\tvalid_0's l2: 0.300922\n",
      "[500]\tvalid_0's l2: 0.300755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.300755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39174.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 17 done.\n",
      "\n",
      "Processing Chunk 18...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.126993\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.596041\n",
      "[100]\tvalid_0's l2: 0.587022\n",
      "[150]\tvalid_0's l2: 0.585252\n",
      "[200]\tvalid_0's l2: 0.584464\n",
      "[250]\tvalid_0's l2: 0.584125\n",
      "[300]\tvalid_0's l2: 0.583868\n",
      "[350]\tvalid_0's l2: 0.583807\n",
      "[400]\tvalid_0's l2: 0.583705\n",
      "Early stopping, best iteration is:\n",
      "[416]\tvalid_0's l2: 0.583695\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.126993\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.32979\n",
      "[100]\tvalid_0's l2: 0.31109\n",
      "[150]\tvalid_0's l2: 0.308372\n",
      "[200]\tvalid_0's l2: 0.307389\n",
      "[250]\tvalid_0's l2: 0.306787\n",
      "[300]\tvalid_0's l2: 0.306343\n",
      "[350]\tvalid_0's l2: 0.306093\n",
      "[400]\tvalid_0's l2: 0.305891\n",
      "[450]\tvalid_0's l2: 0.305783\n",
      "[500]\tvalid_0's l2: 0.305703\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\tvalid_0's l2: 0.305692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39222.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 18 done.\n",
      "\n",
      "Processing Chunk 19...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.148128\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.58644\n",
      "[100]\tvalid_0's l2: 0.576894\n",
      "[150]\tvalid_0's l2: 0.575072\n",
      "[200]\tvalid_0's l2: 0.574392\n",
      "[250]\tvalid_0's l2: 0.574099\n",
      "[300]\tvalid_0's l2: 0.573905\n",
      "[350]\tvalid_0's l2: 0.573715\n",
      "[400]\tvalid_0's l2: 0.573553\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid_0's l2: 0.57348\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.148128\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.324141\n",
      "[100]\tvalid_0's l2: 0.304529\n",
      "[150]\tvalid_0's l2: 0.301844\n",
      "[200]\tvalid_0's l2: 0.300866\n",
      "[250]\tvalid_0's l2: 0.300375\n",
      "[300]\tvalid_0's l2: 0.300121\n",
      "[350]\tvalid_0's l2: 0.299941\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid_0's l2: 0.299904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39769.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 19 done.\n",
      "\n",
      "Processing Chunk 20...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.132453\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.596136\n",
      "[100]\tvalid_0's l2: 0.587119\n",
      "[150]\tvalid_0's l2: 0.585392\n",
      "[200]\tvalid_0's l2: 0.584849\n",
      "[250]\tvalid_0's l2: 0.584516\n",
      "[300]\tvalid_0's l2: 0.584311\n",
      "[350]\tvalid_0's l2: 0.584252\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's l2: 0.584209\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.132453\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.329293\n",
      "[100]\tvalid_0's l2: 0.309453\n",
      "[150]\tvalid_0's l2: 0.306287\n",
      "[200]\tvalid_0's l2: 0.305333\n",
      "[250]\tvalid_0's l2: 0.304715\n",
      "[300]\tvalid_0's l2: 0.304387\n",
      "[350]\tvalid_0's l2: 0.304199\n",
      "[400]\tvalid_0's l2: 0.303986\n",
      "[450]\tvalid_0's l2: 0.303792\n",
      "[500]\tvalid_0's l2: 0.303611\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.303611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40067.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 20 done.\n",
      "\n",
      "Processing Chunk 21...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.136520\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.602506\n",
      "[100]\tvalid_0's l2: 0.593689\n",
      "[150]\tvalid_0's l2: 0.5917\n",
      "[200]\tvalid_0's l2: 0.590881\n",
      "[250]\tvalid_0's l2: 0.59041\n",
      "[300]\tvalid_0's l2: 0.590232\n",
      "[350]\tvalid_0's l2: 0.590185\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's l2: 0.590166\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.136520\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.330094\n",
      "[100]\tvalid_0's l2: 0.311483\n",
      "[150]\tvalid_0's l2: 0.308445\n",
      "[200]\tvalid_0's l2: 0.30739\n",
      "[250]\tvalid_0's l2: 0.30684\n",
      "[300]\tvalid_0's l2: 0.306543\n",
      "[350]\tvalid_0's l2: 0.306239\n",
      "[400]\tvalid_0's l2: 0.306063\n",
      "[450]\tvalid_0's l2: 0.305903\n",
      "[500]\tvalid_0's l2: 0.30583\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.30583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39766.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 21 done.\n",
      "\n",
      "Processing Chunk 22...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.126015\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.596722\n",
      "[100]\tvalid_0's l2: 0.587467\n",
      "[150]\tvalid_0's l2: 0.585889\n",
      "[200]\tvalid_0's l2: 0.585138\n",
      "[250]\tvalid_0's l2: 0.58482\n",
      "[300]\tvalid_0's l2: 0.584638\n",
      "[350]\tvalid_0's l2: 0.584564\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid_0's l2: 0.584551\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.126015\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.330692\n",
      "[100]\tvalid_0's l2: 0.311089\n",
      "[150]\tvalid_0's l2: 0.307693\n",
      "[200]\tvalid_0's l2: 0.306726\n",
      "[250]\tvalid_0's l2: 0.306061\n",
      "[300]\tvalid_0's l2: 0.305597\n",
      "[350]\tvalid_0's l2: 0.3053\n",
      "[400]\tvalid_0's l2: 0.305068\n",
      "[450]\tvalid_0's l2: 0.304882\n",
      "[500]\tvalid_0's l2: 0.304693\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\tvalid_0's l2: 0.304682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39840.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 22 done.\n",
      "\n",
      "Processing Chunk 23...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.132998\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.596769\n",
      "[100]\tvalid_0's l2: 0.587097\n",
      "[150]\tvalid_0's l2: 0.585087\n",
      "[200]\tvalid_0's l2: 0.584427\n",
      "[250]\tvalid_0's l2: 0.584159\n",
      "[300]\tvalid_0's l2: 0.583995\n",
      "[350]\tvalid_0's l2: 0.58384\n",
      "Early stopping, best iteration is:\n",
      "[361]\tvalid_0's l2: 0.58378\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.132998\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.330129\n",
      "[100]\tvalid_0's l2: 0.310641\n",
      "[150]\tvalid_0's l2: 0.307875\n",
      "[200]\tvalid_0's l2: 0.306809\n",
      "[250]\tvalid_0's l2: 0.306317\n",
      "[300]\tvalid_0's l2: 0.30577\n",
      "[350]\tvalid_0's l2: 0.30539\n",
      "[400]\tvalid_0's l2: 0.305153\n",
      "[450]\tvalid_0's l2: 0.305023\n",
      "[500]\tvalid_0's l2: 0.30484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.30484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40197.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 23 done.\n",
      "\n",
      "Processing Chunk 24...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.112805\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.615095\n",
      "[100]\tvalid_0's l2: 0.606106\n",
      "[150]\tvalid_0's l2: 0.604437\n",
      "[200]\tvalid_0's l2: 0.603974\n",
      "[250]\tvalid_0's l2: 0.603545\n",
      "[300]\tvalid_0's l2: 0.603374\n",
      "[350]\tvalid_0's l2: 0.603201\n",
      "[400]\tvalid_0's l2: 0.60313\n",
      "Early stopping, best iteration is:\n",
      "[387]\tvalid_0's l2: 0.603094\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.112805\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.342227\n",
      "[100]\tvalid_0's l2: 0.322725\n",
      "[150]\tvalid_0's l2: 0.319565\n",
      "[200]\tvalid_0's l2: 0.318577\n",
      "[250]\tvalid_0's l2: 0.318068\n",
      "[300]\tvalid_0's l2: 0.317598\n",
      "[350]\tvalid_0's l2: 0.317399\n",
      "[400]\tvalid_0's l2: 0.317147\n",
      "[450]\tvalid_0's l2: 0.317026\n",
      "[500]\tvalid_0's l2: 0.316974\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.316974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39589.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 24 done.\n",
      "\n",
      "Processing Chunk 25...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.023923\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.644962\n",
      "[100]\tvalid_0's l2: 0.636217\n",
      "[150]\tvalid_0's l2: 0.634912\n",
      "[200]\tvalid_0's l2: 0.634646\n",
      "[250]\tvalid_0's l2: 0.63449\n",
      "[300]\tvalid_0's l2: 0.634401\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's l2: 0.634392\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.023923\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.371604\n",
      "[100]\tvalid_0's l2: 0.351076\n",
      "[150]\tvalid_0's l2: 0.34791\n",
      "[200]\tvalid_0's l2: 0.3467\n",
      "[250]\tvalid_0's l2: 0.346195\n",
      "[300]\tvalid_0's l2: 0.345741\n",
      "[350]\tvalid_0's l2: 0.34539\n",
      "[400]\tvalid_0's l2: 0.345104\n",
      "[450]\tvalid_0's l2: 0.344686\n",
      "[500]\tvalid_0's l2: 0.344501\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.344501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38847.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 25 done.\n",
      "\n",
      "Processing Chunk 26...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.046430\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.636934\n",
      "[100]\tvalid_0's l2: 0.627766\n",
      "[150]\tvalid_0's l2: 0.626121\n",
      "[200]\tvalid_0's l2: 0.625739\n",
      "[250]\tvalid_0's l2: 0.625471\n",
      "[300]\tvalid_0's l2: 0.625361\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's l2: 0.625286\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.046430\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.359704\n",
      "[100]\tvalid_0's l2: 0.3382\n",
      "[150]\tvalid_0's l2: 0.334738\n",
      "[200]\tvalid_0's l2: 0.333605\n",
      "[250]\tvalid_0's l2: 0.332882\n",
      "[300]\tvalid_0's l2: 0.3324\n",
      "[350]\tvalid_0's l2: 0.332061\n",
      "[400]\tvalid_0's l2: 0.331842\n",
      "[450]\tvalid_0's l2: 0.331745\n",
      "[500]\tvalid_0's l2: 0.331608\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's l2: 0.331603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39393.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 26 done.\n",
      "\n",
      "Processing Chunk 27...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.142098\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.588605\n",
      "[100]\tvalid_0's l2: 0.577352\n",
      "[150]\tvalid_0's l2: 0.574242\n",
      "[200]\tvalid_0's l2: 0.573131\n",
      "[250]\tvalid_0's l2: 0.572581\n",
      "[300]\tvalid_0's l2: 0.572296\n",
      "[350]\tvalid_0's l2: 0.572033\n",
      "[400]\tvalid_0's l2: 0.571846\n",
      "[450]\tvalid_0's l2: 0.57173\n",
      "Early stopping, best iteration is:\n",
      "[432]\tvalid_0's l2: 0.571729\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.142098\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.321195\n",
      "[100]\tvalid_0's l2: 0.302775\n",
      "[150]\tvalid_0's l2: 0.29981\n",
      "[200]\tvalid_0's l2: 0.298502\n",
      "[250]\tvalid_0's l2: 0.297905\n",
      "[300]\tvalid_0's l2: 0.297479\n",
      "[350]\tvalid_0's l2: 0.297132\n",
      "[400]\tvalid_0's l2: 0.296968\n",
      "[450]\tvalid_0's l2: 0.296723\n",
      "[500]\tvalid_0's l2: 0.29665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.29665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38390.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 27 done.\n",
      "\n",
      "Processing Chunk 28...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.098470\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.618632\n",
      "[100]\tvalid_0's l2: 0.610648\n",
      "[150]\tvalid_0's l2: 0.60881\n",
      "[200]\tvalid_0's l2: 0.608259\n",
      "[250]\tvalid_0's l2: 0.608053\n",
      "[300]\tvalid_0's l2: 0.607935\n",
      "[350]\tvalid_0's l2: 0.607883\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's l2: 0.607878\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.098470\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.349332\n",
      "[100]\tvalid_0's l2: 0.329097\n",
      "[150]\tvalid_0's l2: 0.325613\n",
      "[200]\tvalid_0's l2: 0.324643\n",
      "[250]\tvalid_0's l2: 0.324115\n",
      "[300]\tvalid_0's l2: 0.323668\n",
      "[350]\tvalid_0's l2: 0.323467\n",
      "[400]\tvalid_0's l2: 0.323293\n",
      "[450]\tvalid_0's l2: 0.323193\n",
      "[500]\tvalid_0's l2: 0.323007\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.323007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 37833.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 28 done.\n",
      "\n",
      "Processing Chunk 29...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.123045\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.601924\n",
      "[100]\tvalid_0's l2: 0.59088\n",
      "[150]\tvalid_0's l2: 0.588341\n",
      "[200]\tvalid_0's l2: 0.587705\n",
      "[250]\tvalid_0's l2: 0.58749\n",
      "[300]\tvalid_0's l2: 0.587336\n",
      "[350]\tvalid_0's l2: 0.587223\n",
      "[400]\tvalid_0's l2: 0.587151\n",
      "[450]\tvalid_0's l2: 0.587072\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's l2: 0.587065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.123045\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.335262\n",
      "[100]\tvalid_0's l2: 0.315727\n",
      "[150]\tvalid_0's l2: 0.312643\n",
      "[200]\tvalid_0's l2: 0.311601\n",
      "[250]\tvalid_0's l2: 0.310884\n",
      "[300]\tvalid_0's l2: 0.310521\n",
      "[350]\tvalid_0's l2: 0.310272\n",
      "[400]\tvalid_0's l2: 0.310131\n",
      "[450]\tvalid_0's l2: 0.310005\n",
      "[500]\tvalid_0's l2: 0.309918\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.309918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39016.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 29 done.\n",
      "\n",
      "Processing Chunk 30...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.162497\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.579598\n",
      "[100]\tvalid_0's l2: 0.569795\n",
      "[150]\tvalid_0's l2: 0.567168\n",
      "[200]\tvalid_0's l2: 0.566166\n",
      "[250]\tvalid_0's l2: 0.565566\n",
      "[300]\tvalid_0's l2: 0.565243\n",
      "[350]\tvalid_0's l2: 0.565105\n",
      "Early stopping, best iteration is:\n",
      "[376]\tvalid_0's l2: 0.564934\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.162497\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.313255\n",
      "[100]\tvalid_0's l2: 0.294784\n",
      "[150]\tvalid_0's l2: 0.291801\n",
      "[200]\tvalid_0's l2: 0.290694\n",
      "[250]\tvalid_0's l2: 0.290062\n",
      "[300]\tvalid_0's l2: 0.289615\n",
      "[350]\tvalid_0's l2: 0.28931\n",
      "[400]\tvalid_0's l2: 0.289072\n",
      "[450]\tvalid_0's l2: 0.288949\n",
      "Early stopping, best iteration is:\n",
      "[475]\tvalid_0's l2: 0.28887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40357.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 30 done.\n",
      "\n",
      "Processing Chunk 31...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.105058\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.612674\n",
      "[100]\tvalid_0's l2: 0.602483\n",
      "[150]\tvalid_0's l2: 0.600776\n",
      "[200]\tvalid_0's l2: 0.600281\n",
      "[250]\tvalid_0's l2: 0.600116\n",
      "[300]\tvalid_0's l2: 0.599946\n",
      "[350]\tvalid_0's l2: 0.599792\n",
      "[400]\tvalid_0's l2: 0.599757\n",
      "Early stopping, best iteration is:\n",
      "[412]\tvalid_0's l2: 0.599725\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.105058\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.343594\n",
      "[100]\tvalid_0's l2: 0.323466\n",
      "[150]\tvalid_0's l2: 0.3202\n",
      "[200]\tvalid_0's l2: 0.319343\n",
      "[250]\tvalid_0's l2: 0.318699\n",
      "[300]\tvalid_0's l2: 0.318354\n",
      "[350]\tvalid_0's l2: 0.31807\n",
      "[400]\tvalid_0's l2: 0.317872\n",
      "[450]\tvalid_0's l2: 0.31773\n",
      "[500]\tvalid_0's l2: 0.317511\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.317511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39145.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 31 done.\n",
      "\n",
      "Processing Chunk 32...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.092367\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.618121\n",
      "[100]\tvalid_0's l2: 0.607453\n",
      "[150]\tvalid_0's l2: 0.605779\n",
      "[200]\tvalid_0's l2: 0.605474\n",
      "[250]\tvalid_0's l2: 0.605294\n",
      "[300]\tvalid_0's l2: 0.605175\n",
      "[350]\tvalid_0's l2: 0.605148\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid_0's l2: 0.6051\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.092367\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.349234\n",
      "[100]\tvalid_0's l2: 0.328737\n",
      "[150]\tvalid_0's l2: 0.325062\n",
      "[200]\tvalid_0's l2: 0.323895\n",
      "[250]\tvalid_0's l2: 0.323362\n",
      "[300]\tvalid_0's l2: 0.322987\n",
      "[350]\tvalid_0's l2: 0.32275\n",
      "[400]\tvalid_0's l2: 0.322581\n",
      "[450]\tvalid_0's l2: 0.322376\n",
      "[500]\tvalid_0's l2: 0.322212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.322209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39717.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 32 done.\n",
      "\n",
      "Processing Chunk 33...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.027490\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.641769\n",
      "[100]\tvalid_0's l2: 0.631888\n",
      "[150]\tvalid_0's l2: 0.630186\n",
      "[200]\tvalid_0's l2: 0.629686\n",
      "[250]\tvalid_0's l2: 0.629362\n",
      "[300]\tvalid_0's l2: 0.629248\n",
      "Early stopping, best iteration is:\n",
      "[295]\tvalid_0's l2: 0.629229\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.027490\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.358251\n",
      "[100]\tvalid_0's l2: 0.337131\n",
      "[150]\tvalid_0's l2: 0.33374\n",
      "[200]\tvalid_0's l2: 0.332191\n",
      "[250]\tvalid_0's l2: 0.331497\n",
      "[300]\tvalid_0's l2: 0.331152\n",
      "[350]\tvalid_0's l2: 0.330854\n",
      "[400]\tvalid_0's l2: 0.330632\n",
      "[450]\tvalid_0's l2: 0.330542\n",
      "[500]\tvalid_0's l2: 0.330378\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.330378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38266.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 33 done.\n",
      "\n",
      "Processing Chunk 34...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.017895\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.647774\n",
      "[100]\tvalid_0's l2: 0.63678\n",
      "[150]\tvalid_0's l2: 0.634587\n",
      "[200]\tvalid_0's l2: 0.633852\n",
      "[250]\tvalid_0's l2: 0.633457\n",
      "[300]\tvalid_0's l2: 0.633052\n",
      "[350]\tvalid_0's l2: 0.632901\n",
      "Early stopping, best iteration is:\n",
      "[373]\tvalid_0's l2: 0.632774\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.017895\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.365186\n",
      "[100]\tvalid_0's l2: 0.344359\n",
      "[150]\tvalid_0's l2: 0.341388\n",
      "[200]\tvalid_0's l2: 0.340431\n",
      "[250]\tvalid_0's l2: 0.339815\n",
      "[300]\tvalid_0's l2: 0.339366\n",
      "[350]\tvalid_0's l2: 0.33897\n",
      "[400]\tvalid_0's l2: 0.338897\n",
      "[450]\tvalid_0's l2: 0.338723\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's l2: 0.338684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38680.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 34 done.\n",
      "\n",
      "Processing Chunk 35...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.172758\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.56981\n",
      "[100]\tvalid_0's l2: 0.557391\n",
      "[150]\tvalid_0's l2: 0.553588\n",
      "[200]\tvalid_0's l2: 0.552268\n",
      "[250]\tvalid_0's l2: 0.551407\n",
      "[300]\tvalid_0's l2: 0.550868\n",
      "[350]\tvalid_0's l2: 0.550313\n",
      "[400]\tvalid_0's l2: 0.550039\n",
      "[450]\tvalid_0's l2: 0.549753\n",
      "[500]\tvalid_0's l2: 0.54957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.54957\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.172758\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.311032\n",
      "[100]\tvalid_0's l2: 0.293564\n",
      "[150]\tvalid_0's l2: 0.290422\n",
      "[200]\tvalid_0's l2: 0.289123\n",
      "[250]\tvalid_0's l2: 0.288331\n",
      "[300]\tvalid_0's l2: 0.287842\n",
      "[350]\tvalid_0's l2: 0.287493\n",
      "[400]\tvalid_0's l2: 0.287235\n",
      "[450]\tvalid_0's l2: 0.287036\n",
      "[500]\tvalid_0's l2: 0.286922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[492]\tvalid_0's l2: 0.286909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39012.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 35 done.\n",
      "\n",
      "Processing Chunk 36...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.173830\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.569305\n",
      "[100]\tvalid_0's l2: 0.556185\n",
      "[150]\tvalid_0's l2: 0.552125\n",
      "[200]\tvalid_0's l2: 0.550899\n",
      "[250]\tvalid_0's l2: 0.550372\n",
      "[300]\tvalid_0's l2: 0.54997\n",
      "[350]\tvalid_0's l2: 0.549658\n",
      "[400]\tvalid_0's l2: 0.549433\n",
      "[450]\tvalid_0's l2: 0.549321\n",
      "Early stopping, best iteration is:\n",
      "[478]\tvalid_0's l2: 0.549263\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.173830\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.314435\n",
      "[100]\tvalid_0's l2: 0.295516\n",
      "[150]\tvalid_0's l2: 0.291929\n",
      "[200]\tvalid_0's l2: 0.290571\n",
      "[250]\tvalid_0's l2: 0.289899\n",
      "[300]\tvalid_0's l2: 0.28947\n",
      "[350]\tvalid_0's l2: 0.289125\n",
      "[400]\tvalid_0's l2: 0.288918\n",
      "[450]\tvalid_0's l2: 0.288724\n",
      "[500]\tvalid_0's l2: 0.288558\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.288558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39520.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 36 done.\n",
      "\n",
      "Processing Chunk 37...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.209575\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.548948\n",
      "[100]\tvalid_0's l2: 0.538062\n",
      "[150]\tvalid_0's l2: 0.535126\n",
      "[200]\tvalid_0's l2: 0.534049\n",
      "[250]\tvalid_0's l2: 0.533416\n",
      "[300]\tvalid_0's l2: 0.532948\n",
      "[350]\tvalid_0's l2: 0.532582\n",
      "[400]\tvalid_0's l2: 0.532385\n",
      "[450]\tvalid_0's l2: 0.532198\n",
      "[500]\tvalid_0's l2: 0.532035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.532035\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.209575\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.303117\n",
      "[100]\tvalid_0's l2: 0.286052\n",
      "[150]\tvalid_0's l2: 0.282769\n",
      "[200]\tvalid_0's l2: 0.28148\n",
      "[250]\tvalid_0's l2: 0.280761\n",
      "[300]\tvalid_0's l2: 0.280355\n",
      "[350]\tvalid_0's l2: 0.28006\n",
      "[400]\tvalid_0's l2: 0.279767\n",
      "[450]\tvalid_0's l2: 0.279586\n",
      "[500]\tvalid_0's l2: 0.279412\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.279412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39527.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 37 done.\n",
      "\n",
      "Processing Chunk 38...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.204533\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.553443\n",
      "[100]\tvalid_0's l2: 0.542377\n",
      "[150]\tvalid_0's l2: 0.539388\n",
      "[200]\tvalid_0's l2: 0.53843\n",
      "[250]\tvalid_0's l2: 0.537848\n",
      "[300]\tvalid_0's l2: 0.537405\n",
      "[350]\tvalid_0's l2: 0.537184\n",
      "[400]\tvalid_0's l2: 0.53697\n",
      "[450]\tvalid_0's l2: 0.536844\n",
      "[500]\tvalid_0's l2: 0.536691\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.536686\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.204533\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.301202\n",
      "[100]\tvalid_0's l2: 0.285156\n",
      "[150]\tvalid_0's l2: 0.282448\n",
      "[200]\tvalid_0's l2: 0.281307\n",
      "[250]\tvalid_0's l2: 0.280791\n",
      "[300]\tvalid_0's l2: 0.280463\n",
      "[350]\tvalid_0's l2: 0.280164\n",
      "[400]\tvalid_0's l2: 0.279875\n",
      "[450]\tvalid_0's l2: 0.279635\n",
      "[500]\tvalid_0's l2: 0.279465\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.279465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39772.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 38 done.\n",
      "\n",
      "Processing Chunk 39...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.187803\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.571888\n",
      "[100]\tvalid_0's l2: 0.559811\n",
      "[150]\tvalid_0's l2: 0.555986\n",
      "[200]\tvalid_0's l2: 0.55462\n",
      "[250]\tvalid_0's l2: 0.553916\n",
      "[300]\tvalid_0's l2: 0.553467\n",
      "[350]\tvalid_0's l2: 0.552959\n",
      "[400]\tvalid_0's l2: 0.552598\n",
      "[450]\tvalid_0's l2: 0.552319\n",
      "[500]\tvalid_0's l2: 0.552168\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[487]\tvalid_0's l2: 0.552159\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.187803\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.309861\n",
      "[100]\tvalid_0's l2: 0.292506\n",
      "[150]\tvalid_0's l2: 0.289545\n",
      "[200]\tvalid_0's l2: 0.288339\n",
      "[250]\tvalid_0's l2: 0.287674\n",
      "[300]\tvalid_0's l2: 0.287274\n",
      "[350]\tvalid_0's l2: 0.286998\n",
      "[400]\tvalid_0's l2: 0.286811\n",
      "[450]\tvalid_0's l2: 0.286625\n",
      "[500]\tvalid_0's l2: 0.286484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.286481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38970.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 39 done.\n",
      "\n",
      "Processing Chunk 40...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.239377\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.541746\n",
      "[100]\tvalid_0's l2: 0.529141\n",
      "[150]\tvalid_0's l2: 0.525873\n",
      "[200]\tvalid_0's l2: 0.524455\n",
      "[250]\tvalid_0's l2: 0.523514\n",
      "[300]\tvalid_0's l2: 0.523023\n",
      "[350]\tvalid_0's l2: 0.522712\n",
      "[400]\tvalid_0's l2: 0.522372\n",
      "[450]\tvalid_0's l2: 0.522265\n",
      "[500]\tvalid_0's l2: 0.522048\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[491]\tvalid_0's l2: 0.522035\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.239377\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.300333\n",
      "[100]\tvalid_0's l2: 0.283509\n",
      "[150]\tvalid_0's l2: 0.28038\n",
      "[200]\tvalid_0's l2: 0.279144\n",
      "[250]\tvalid_0's l2: 0.278417\n",
      "[300]\tvalid_0's l2: 0.277915\n",
      "[350]\tvalid_0's l2: 0.277607\n",
      "[400]\tvalid_0's l2: 0.277367\n",
      "[450]\tvalid_0's l2: 0.277162\n",
      "[500]\tvalid_0's l2: 0.276983\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.27698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39779.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 40 done.\n",
      "\n",
      "Processing Chunk 41...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.182710\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.565181\n",
      "[100]\tvalid_0's l2: 0.552317\n",
      "[150]\tvalid_0's l2: 0.548471\n",
      "[200]\tvalid_0's l2: 0.547017\n",
      "[250]\tvalid_0's l2: 0.546293\n",
      "[300]\tvalid_0's l2: 0.545865\n",
      "[350]\tvalid_0's l2: 0.545438\n",
      "[400]\tvalid_0's l2: 0.545325\n",
      "[450]\tvalid_0's l2: 0.545217\n",
      "[500]\tvalid_0's l2: 0.545067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.545067\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.182710\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.305582\n",
      "[100]\tvalid_0's l2: 0.288812\n",
      "[150]\tvalid_0's l2: 0.285805\n",
      "[200]\tvalid_0's l2: 0.2847\n",
      "[250]\tvalid_0's l2: 0.284003\n",
      "[300]\tvalid_0's l2: 0.283495\n",
      "[350]\tvalid_0's l2: 0.283219\n",
      "[400]\tvalid_0's l2: 0.282973\n",
      "[450]\tvalid_0's l2: 0.282782\n",
      "[500]\tvalid_0's l2: 0.282638\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.282637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38467.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 41 done.\n",
      "\n",
      "Processing Chunk 42...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.151510\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.578987\n",
      "[100]\tvalid_0's l2: 0.564623\n",
      "[150]\tvalid_0's l2: 0.560905\n",
      "[200]\tvalid_0's l2: 0.559213\n",
      "[250]\tvalid_0's l2: 0.558491\n",
      "[300]\tvalid_0's l2: 0.558007\n",
      "[350]\tvalid_0's l2: 0.557528\n",
      "[400]\tvalid_0's l2: 0.557229\n",
      "[450]\tvalid_0's l2: 0.557084\n",
      "[500]\tvalid_0's l2: 0.556948\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.556948\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.151510\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.309813\n",
      "[100]\tvalid_0's l2: 0.29222\n",
      "[150]\tvalid_0's l2: 0.289429\n",
      "[200]\tvalid_0's l2: 0.288325\n",
      "[250]\tvalid_0's l2: 0.28779\n",
      "[300]\tvalid_0's l2: 0.287447\n",
      "[350]\tvalid_0's l2: 0.287179\n",
      "[400]\tvalid_0's l2: 0.286994\n",
      "[450]\tvalid_0's l2: 0.286862\n",
      "[500]\tvalid_0's l2: 0.286716\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.286716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39547.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 42 done.\n",
      "\n",
      "Processing Chunk 43...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.131197\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.58361\n",
      "[100]\tvalid_0's l2: 0.570292\n",
      "[150]\tvalid_0's l2: 0.566654\n",
      "[200]\tvalid_0's l2: 0.565051\n",
      "[250]\tvalid_0's l2: 0.564322\n",
      "[300]\tvalid_0's l2: 0.563964\n",
      "[350]\tvalid_0's l2: 0.563733\n",
      "[400]\tvalid_0's l2: 0.563625\n",
      "[450]\tvalid_0's l2: 0.563522\n",
      "Early stopping, best iteration is:\n",
      "[470]\tvalid_0's l2: 0.563464\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.131197\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.311956\n",
      "[100]\tvalid_0's l2: 0.294088\n",
      "[150]\tvalid_0's l2: 0.290667\n",
      "[200]\tvalid_0's l2: 0.289275\n",
      "[250]\tvalid_0's l2: 0.288672\n",
      "[300]\tvalid_0's l2: 0.288363\n",
      "[350]\tvalid_0's l2: 0.288091\n",
      "[400]\tvalid_0's l2: 0.287905\n",
      "[450]\tvalid_0's l2: 0.287707\n",
      "[500]\tvalid_0's l2: 0.287531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.287531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39568.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 43 done.\n",
      "\n",
      "Processing Chunk 44...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.166155\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.570026\n",
      "[100]\tvalid_0's l2: 0.55782\n",
      "[150]\tvalid_0's l2: 0.554798\n",
      "[200]\tvalid_0's l2: 0.553602\n",
      "[250]\tvalid_0's l2: 0.552872\n",
      "[300]\tvalid_0's l2: 0.552365\n",
      "[350]\tvalid_0's l2: 0.552225\n",
      "[400]\tvalid_0's l2: 0.55223\n",
      "Early stopping, best iteration is:\n",
      "[388]\tvalid_0's l2: 0.552201\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.166155\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.306576\n",
      "[100]\tvalid_0's l2: 0.2886\n",
      "[150]\tvalid_0's l2: 0.285422\n",
      "[200]\tvalid_0's l2: 0.284337\n",
      "[250]\tvalid_0's l2: 0.283869\n",
      "[300]\tvalid_0's l2: 0.283508\n",
      "[350]\tvalid_0's l2: 0.283253\n",
      "[400]\tvalid_0's l2: 0.283016\n",
      "[450]\tvalid_0's l2: 0.282838\n",
      "[500]\tvalid_0's l2: 0.282738\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.282737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39504.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 44 done.\n",
      "\n",
      "Processing Chunk 45...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.164095\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.573001\n",
      "[100]\tvalid_0's l2: 0.562425\n",
      "[150]\tvalid_0's l2: 0.559374\n",
      "[200]\tvalid_0's l2: 0.558602\n",
      "[250]\tvalid_0's l2: 0.558165\n",
      "[300]\tvalid_0's l2: 0.557872\n",
      "[350]\tvalid_0's l2: 0.557665\n",
      "[400]\tvalid_0's l2: 0.557472\n",
      "[450]\tvalid_0's l2: 0.557294\n",
      "[500]\tvalid_0's l2: 0.557213\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\tvalid_0's l2: 0.55721\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.164095\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.307304\n",
      "[100]\tvalid_0's l2: 0.289592\n",
      "[150]\tvalid_0's l2: 0.286458\n",
      "[200]\tvalid_0's l2: 0.285388\n",
      "[250]\tvalid_0's l2: 0.284898\n",
      "[300]\tvalid_0's l2: 0.284577\n",
      "[350]\tvalid_0's l2: 0.284283\n",
      "[400]\tvalid_0's l2: 0.284105\n",
      "[450]\tvalid_0's l2: 0.283958\n",
      "[500]\tvalid_0's l2: 0.283825\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.283824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38813.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 45 done.\n",
      "\n",
      "Processing Chunk 46...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.137833\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.57567\n",
      "[100]\tvalid_0's l2: 0.562889\n",
      "[150]\tvalid_0's l2: 0.559569\n",
      "[200]\tvalid_0's l2: 0.558241\n",
      "[250]\tvalid_0's l2: 0.557527\n",
      "[300]\tvalid_0's l2: 0.557133\n",
      "[350]\tvalid_0's l2: 0.556858\n",
      "[400]\tvalid_0's l2: 0.556599\n",
      "[450]\tvalid_0's l2: 0.556476\n",
      "[500]\tvalid_0's l2: 0.556305\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[493]\tvalid_0's l2: 0.556287\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.137833\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.312277\n",
      "[100]\tvalid_0's l2: 0.294976\n",
      "[150]\tvalid_0's l2: 0.291936\n",
      "[200]\tvalid_0's l2: 0.29088\n",
      "[250]\tvalid_0's l2: 0.290282\n",
      "[300]\tvalid_0's l2: 0.289874\n",
      "[350]\tvalid_0's l2: 0.289561\n",
      "[400]\tvalid_0's l2: 0.289321\n",
      "[450]\tvalid_0's l2: 0.289116\n",
      "[500]\tvalid_0's l2: 0.288949\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.288949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 37945.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 46 done.\n",
      "\n",
      "Processing Chunk 47...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.146365\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.577488\n",
      "[100]\tvalid_0's l2: 0.565237\n",
      "[150]\tvalid_0's l2: 0.560882\n",
      "[200]\tvalid_0's l2: 0.559193\n",
      "[250]\tvalid_0's l2: 0.558348\n",
      "[300]\tvalid_0's l2: 0.557874\n",
      "[350]\tvalid_0's l2: 0.557553\n",
      "[400]\tvalid_0's l2: 0.557175\n",
      "[450]\tvalid_0's l2: 0.557001\n",
      "[500]\tvalid_0's l2: 0.556859\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[493]\tvalid_0's l2: 0.556851\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.146365\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.313651\n",
      "[100]\tvalid_0's l2: 0.296777\n",
      "[150]\tvalid_0's l2: 0.29379\n",
      "[200]\tvalid_0's l2: 0.292596\n",
      "[250]\tvalid_0's l2: 0.291884\n",
      "[300]\tvalid_0's l2: 0.291422\n",
      "[350]\tvalid_0's l2: 0.291063\n",
      "[400]\tvalid_0's l2: 0.290758\n",
      "[450]\tvalid_0's l2: 0.290554\n",
      "[500]\tvalid_0's l2: 0.290343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.290343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39070.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 47 done.\n",
      "\n",
      "Processing Chunk 48...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.156218\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.575421\n",
      "[100]\tvalid_0's l2: 0.561845\n",
      "[150]\tvalid_0's l2: 0.557625\n",
      "[200]\tvalid_0's l2: 0.556133\n",
      "[250]\tvalid_0's l2: 0.555189\n",
      "[300]\tvalid_0's l2: 0.554716\n",
      "[350]\tvalid_0's l2: 0.554427\n",
      "[400]\tvalid_0's l2: 0.554188\n",
      "[450]\tvalid_0's l2: 0.553962\n",
      "[500]\tvalid_0's l2: 0.553862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.553862\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.156218\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.309073\n",
      "[100]\tvalid_0's l2: 0.291548\n",
      "[150]\tvalid_0's l2: 0.288374\n",
      "[200]\tvalid_0's l2: 0.287274\n",
      "[250]\tvalid_0's l2: 0.28649\n",
      "[300]\tvalid_0's l2: 0.286049\n",
      "[350]\tvalid_0's l2: 0.28577\n",
      "[400]\tvalid_0's l2: 0.285564\n",
      "[450]\tvalid_0's l2: 0.285313\n",
      "[500]\tvalid_0's l2: 0.285117\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.285116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39188.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 48 done.\n",
      "\n",
      "Processing Chunk 49...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.224757\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.538633\n",
      "[100]\tvalid_0's l2: 0.523711\n",
      "[150]\tvalid_0's l2: 0.517955\n",
      "[200]\tvalid_0's l2: 0.515737\n",
      "[250]\tvalid_0's l2: 0.514487\n",
      "[300]\tvalid_0's l2: 0.513733\n",
      "[350]\tvalid_0's l2: 0.513338\n",
      "[400]\tvalid_0's l2: 0.512989\n",
      "[450]\tvalid_0's l2: 0.512876\n",
      "Early stopping, best iteration is:\n",
      "[473]\tvalid_0's l2: 0.512796\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 805\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.224757\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.3112\n",
      "[100]\tvalid_0's l2: 0.294963\n",
      "[150]\tvalid_0's l2: 0.291847\n",
      "[200]\tvalid_0's l2: 0.290704\n",
      "[250]\tvalid_0's l2: 0.290005\n",
      "[300]\tvalid_0's l2: 0.289515\n",
      "[350]\tvalid_0's l2: 0.289147\n",
      "[400]\tvalid_0's l2: 0.288836\n",
      "[450]\tvalid_0's l2: 0.288594\n",
      "[500]\tvalid_0's l2: 0.288356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.288349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40140.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 49 done.\n",
      "\n",
      "Processing Chunk 50...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.233473\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.529383\n",
      "[100]\tvalid_0's l2: 0.513139\n",
      "[150]\tvalid_0's l2: 0.506649\n",
      "[200]\tvalid_0's l2: 0.504357\n",
      "[250]\tvalid_0's l2: 0.503106\n",
      "[300]\tvalid_0's l2: 0.502504\n",
      "[350]\tvalid_0's l2: 0.501838\n",
      "[400]\tvalid_0's l2: 0.501482\n",
      "[450]\tvalid_0's l2: 0.501149\n",
      "[500]\tvalid_0's l2: 0.500782\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.500782\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 805\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.233473\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.307101\n",
      "[100]\tvalid_0's l2: 0.291071\n",
      "[150]\tvalid_0's l2: 0.288168\n",
      "[200]\tvalid_0's l2: 0.286824\n",
      "[250]\tvalid_0's l2: 0.286203\n",
      "[300]\tvalid_0's l2: 0.285694\n",
      "[350]\tvalid_0's l2: 0.285335\n",
      "[400]\tvalid_0's l2: 0.285024\n",
      "[450]\tvalid_0's l2: 0.284888\n",
      "[500]\tvalid_0's l2: 0.2847\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.284698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40047.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 50 done.\n",
      "\n",
      "Processing Chunk 51...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 744\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.257178\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.520733\n",
      "[100]\tvalid_0's l2: 0.499842\n",
      "[150]\tvalid_0's l2: 0.491571\n",
      "[200]\tvalid_0's l2: 0.488734\n",
      "[250]\tvalid_0's l2: 0.487081\n",
      "[300]\tvalid_0's l2: 0.485744\n",
      "[350]\tvalid_0's l2: 0.484982\n",
      "[400]\tvalid_0's l2: 0.484626\n",
      "[450]\tvalid_0's l2: 0.484255\n",
      "[500]\tvalid_0's l2: 0.4841\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.484099\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 791\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.257178\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.303183\n",
      "[100]\tvalid_0's l2: 0.286963\n",
      "[150]\tvalid_0's l2: 0.283857\n",
      "[200]\tvalid_0's l2: 0.282378\n",
      "[250]\tvalid_0's l2: 0.281599\n",
      "[300]\tvalid_0's l2: 0.281103\n",
      "[350]\tvalid_0's l2: 0.280739\n",
      "[400]\tvalid_0's l2: 0.280405\n",
      "[450]\tvalid_0's l2: 0.280161\n",
      "[500]\tvalid_0's l2: 0.279922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.279919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40505.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 51 done.\n",
      "\n",
      "Processing Chunk 52...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.233562\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.529956\n",
      "[100]\tvalid_0's l2: 0.506623\n",
      "[150]\tvalid_0's l2: 0.498953\n",
      "[200]\tvalid_0's l2: 0.495734\n",
      "[250]\tvalid_0's l2: 0.494111\n",
      "[300]\tvalid_0's l2: 0.492794\n",
      "[350]\tvalid_0's l2: 0.492025\n",
      "[400]\tvalid_0's l2: 0.49151\n",
      "[450]\tvalid_0's l2: 0.491173\n",
      "[500]\tvalid_0's l2: 0.490832\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.490832\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.233562\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.302799\n",
      "[100]\tvalid_0's l2: 0.286477\n",
      "[150]\tvalid_0's l2: 0.283654\n",
      "[200]\tvalid_0's l2: 0.282416\n",
      "[250]\tvalid_0's l2: 0.281496\n",
      "[300]\tvalid_0's l2: 0.280918\n",
      "[350]\tvalid_0's l2: 0.280603\n",
      "[400]\tvalid_0's l2: 0.280255\n",
      "[450]\tvalid_0's l2: 0.279909\n",
      "[500]\tvalid_0's l2: 0.279693\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.279693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40467.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 52 done.\n",
      "\n",
      "Processing Chunk 53...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 749\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.195520\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.544897\n",
      "[100]\tvalid_0's l2: 0.524935\n",
      "[150]\tvalid_0's l2: 0.518623\n",
      "[200]\tvalid_0's l2: 0.515866\n",
      "[250]\tvalid_0's l2: 0.514177\n",
      "[300]\tvalid_0's l2: 0.513121\n",
      "[350]\tvalid_0's l2: 0.512528\n",
      "[400]\tvalid_0's l2: 0.512082\n",
      "[450]\tvalid_0's l2: 0.511716\n",
      "[500]\tvalid_0's l2: 0.511597\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.511597\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.195520\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.323475\n",
      "[100]\tvalid_0's l2: 0.306776\n",
      "[150]\tvalid_0's l2: 0.303388\n",
      "[200]\tvalid_0's l2: 0.301905\n",
      "[250]\tvalid_0's l2: 0.300847\n",
      "[300]\tvalid_0's l2: 0.300152\n",
      "[350]\tvalid_0's l2: 0.299647\n",
      "[400]\tvalid_0's l2: 0.299372\n",
      "[450]\tvalid_0's l2: 0.299083\n",
      "[500]\tvalid_0's l2: 0.298913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.298911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39773.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 53 done.\n",
      "\n",
      "Processing Chunk 54...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.267993\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.512731\n",
      "[100]\tvalid_0's l2: 0.492146\n",
      "[150]\tvalid_0's l2: 0.485446\n",
      "[200]\tvalid_0's l2: 0.482686\n",
      "[250]\tvalid_0's l2: 0.481374\n",
      "[300]\tvalid_0's l2: 0.480487\n",
      "[350]\tvalid_0's l2: 0.479897\n",
      "[400]\tvalid_0's l2: 0.479512\n",
      "[450]\tvalid_0's l2: 0.479145\n",
      "Early stopping, best iteration is:\n",
      "[469]\tvalid_0's l2: 0.479095\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 810\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.267993\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.30484\n",
      "[100]\tvalid_0's l2: 0.288153\n",
      "[150]\tvalid_0's l2: 0.284714\n",
      "[200]\tvalid_0's l2: 0.283453\n",
      "[250]\tvalid_0's l2: 0.282807\n",
      "[300]\tvalid_0's l2: 0.282255\n",
      "[350]\tvalid_0's l2: 0.281873\n",
      "[400]\tvalid_0's l2: 0.281552\n",
      "[450]\tvalid_0's l2: 0.281362\n",
      "[500]\tvalid_0's l2: 0.281161\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[493]\tvalid_0's l2: 0.281157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39911.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 54 done.\n",
      "\n",
      "Processing Chunk 55...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 742\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.237278\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.528322\n",
      "[100]\tvalid_0's l2: 0.50682\n",
      "[150]\tvalid_0's l2: 0.502309\n",
      "[200]\tvalid_0's l2: 0.499648\n",
      "[250]\tvalid_0's l2: 0.497988\n",
      "[300]\tvalid_0's l2: 0.496848\n",
      "[350]\tvalid_0's l2: 0.495925\n",
      "[400]\tvalid_0's l2: 0.49541\n",
      "[450]\tvalid_0's l2: 0.495042\n",
      "[500]\tvalid_0's l2: 0.494689\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.494689\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 788\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.237278\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.311062\n",
      "[100]\tvalid_0's l2: 0.293913\n",
      "[150]\tvalid_0's l2: 0.290263\n",
      "[200]\tvalid_0's l2: 0.288764\n",
      "[250]\tvalid_0's l2: 0.287947\n",
      "[300]\tvalid_0's l2: 0.287244\n",
      "[350]\tvalid_0's l2: 0.286942\n",
      "[400]\tvalid_0's l2: 0.286597\n",
      "[450]\tvalid_0's l2: 0.286331\n",
      "[500]\tvalid_0's l2: 0.286109\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.286108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40544.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 55 done.\n",
      "\n",
      "Processing Chunk 56...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 740\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.265045\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.517648\n",
      "[100]\tvalid_0's l2: 0.499301\n",
      "[150]\tvalid_0's l2: 0.49317\n",
      "[200]\tvalid_0's l2: 0.489973\n",
      "[250]\tvalid_0's l2: 0.488477\n",
      "[300]\tvalid_0's l2: 0.487452\n",
      "[350]\tvalid_0's l2: 0.487007\n",
      "[400]\tvalid_0's l2: 0.486638\n",
      "[450]\tvalid_0's l2: 0.486477\n",
      "[500]\tvalid_0's l2: 0.486213\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.486213\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.265045\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.310131\n",
      "[100]\tvalid_0's l2: 0.293958\n",
      "[150]\tvalid_0's l2: 0.290841\n",
      "[200]\tvalid_0's l2: 0.289773\n",
      "[250]\tvalid_0's l2: 0.289091\n",
      "[300]\tvalid_0's l2: 0.28859\n",
      "[350]\tvalid_0's l2: 0.288195\n",
      "[400]\tvalid_0's l2: 0.287931\n",
      "[450]\tvalid_0's l2: 0.287762\n",
      "[500]\tvalid_0's l2: 0.287575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.287575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40507.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 56 done.\n",
      "\n",
      "Processing Chunk 57...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.249557\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.51876\n",
      "[100]\tvalid_0's l2: 0.499584\n",
      "[150]\tvalid_0's l2: 0.492489\n",
      "[200]\tvalid_0's l2: 0.489468\n",
      "[250]\tvalid_0's l2: 0.487787\n",
      "[300]\tvalid_0's l2: 0.486901\n",
      "[350]\tvalid_0's l2: 0.486139\n",
      "[400]\tvalid_0's l2: 0.485661\n",
      "[450]\tvalid_0's l2: 0.485392\n",
      "[500]\tvalid_0's l2: 0.485142\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.485142\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 779\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.249557\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.303853\n",
      "[100]\tvalid_0's l2: 0.287696\n",
      "[150]\tvalid_0's l2: 0.28481\n",
      "[200]\tvalid_0's l2: 0.283518\n",
      "[250]\tvalid_0's l2: 0.282899\n",
      "[300]\tvalid_0's l2: 0.282339\n",
      "[350]\tvalid_0's l2: 0.281963\n",
      "[400]\tvalid_0's l2: 0.281672\n",
      "[450]\tvalid_0's l2: 0.281488\n",
      "[500]\tvalid_0's l2: 0.281265\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.281265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40260.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 57 done.\n",
      "\n",
      "Processing Chunk 58...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.179412\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.564468\n",
      "[100]\tvalid_0's l2: 0.548532\n",
      "[150]\tvalid_0's l2: 0.543491\n",
      "[200]\tvalid_0's l2: 0.541876\n",
      "[250]\tvalid_0's l2: 0.540665\n",
      "[300]\tvalid_0's l2: 0.539942\n",
      "[350]\tvalid_0's l2: 0.539431\n",
      "[400]\tvalid_0's l2: 0.539085\n",
      "[450]\tvalid_0's l2: 0.538793\n",
      "[500]\tvalid_0's l2: 0.538662\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.538661\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.179412\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.316391\n",
      "[100]\tvalid_0's l2: 0.298551\n",
      "[150]\tvalid_0's l2: 0.294886\n",
      "[200]\tvalid_0's l2: 0.293303\n",
      "[250]\tvalid_0's l2: 0.292578\n",
      "[300]\tvalid_0's l2: 0.292\n",
      "[350]\tvalid_0's l2: 0.291478\n",
      "[400]\tvalid_0's l2: 0.291178\n",
      "[450]\tvalid_0's l2: 0.290951\n",
      "[500]\tvalid_0's l2: 0.29076\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.290757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40319.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 58 done.\n",
      "\n",
      "Processing Chunk 59...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.164813\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.569244\n",
      "[100]\tvalid_0's l2: 0.556727\n",
      "[150]\tvalid_0's l2: 0.553255\n",
      "[200]\tvalid_0's l2: 0.55181\n",
      "[250]\tvalid_0's l2: 0.550947\n",
      "[300]\tvalid_0's l2: 0.55048\n",
      "[350]\tvalid_0's l2: 0.550088\n",
      "[400]\tvalid_0's l2: 0.549901\n",
      "[450]\tvalid_0's l2: 0.549658\n",
      "[500]\tvalid_0's l2: 0.549522\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's l2: 0.549517\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.164813\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.310278\n",
      "[100]\tvalid_0's l2: 0.292446\n",
      "[150]\tvalid_0's l2: 0.289415\n",
      "[200]\tvalid_0's l2: 0.288335\n",
      "[250]\tvalid_0's l2: 0.287724\n",
      "[300]\tvalid_0's l2: 0.287297\n",
      "[350]\tvalid_0's l2: 0.286931\n",
      "[400]\tvalid_0's l2: 0.286728\n",
      "[450]\tvalid_0's l2: 0.286494\n",
      "[500]\tvalid_0's l2: 0.28634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.28634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39668.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 59 done.\n",
      "\n",
      "Processing Chunk 60...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.216645\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.539785\n",
      "[100]\tvalid_0's l2: 0.523937\n",
      "[150]\tvalid_0's l2: 0.51871\n",
      "[200]\tvalid_0's l2: 0.516189\n",
      "[250]\tvalid_0's l2: 0.515153\n",
      "[300]\tvalid_0's l2: 0.514482\n",
      "[350]\tvalid_0's l2: 0.513909\n",
      "[400]\tvalid_0's l2: 0.513511\n",
      "[450]\tvalid_0's l2: 0.513098\n",
      "[500]\tvalid_0's l2: 0.512824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.512824\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 809\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.216645\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.306363\n",
      "[100]\tvalid_0's l2: 0.289453\n",
      "[150]\tvalid_0's l2: 0.286296\n",
      "[200]\tvalid_0's l2: 0.284951\n",
      "[250]\tvalid_0's l2: 0.284201\n",
      "[300]\tvalid_0's l2: 0.283708\n",
      "[350]\tvalid_0's l2: 0.283343\n",
      "[400]\tvalid_0's l2: 0.283095\n",
      "[450]\tvalid_0's l2: 0.282911\n",
      "[500]\tvalid_0's l2: 0.282672\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.282672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38921.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 60 done.\n",
      "\n",
      "Processing Chunk 61...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.187608\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.558551\n",
      "[100]\tvalid_0's l2: 0.546166\n",
      "[150]\tvalid_0's l2: 0.542478\n",
      "[200]\tvalid_0's l2: 0.540591\n",
      "[250]\tvalid_0's l2: 0.539701\n",
      "[300]\tvalid_0's l2: 0.539205\n",
      "[350]\tvalid_0's l2: 0.538851\n",
      "[400]\tvalid_0's l2: 0.538483\n",
      "[450]\tvalid_0's l2: 0.53837\n",
      "[500]\tvalid_0's l2: 0.538279\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\tvalid_0's l2: 0.538264\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.187608\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.305306\n",
      "[100]\tvalid_0's l2: 0.288894\n",
      "[150]\tvalid_0's l2: 0.285959\n",
      "[200]\tvalid_0's l2: 0.284995\n",
      "[250]\tvalid_0's l2: 0.284571\n",
      "[300]\tvalid_0's l2: 0.284257\n",
      "[350]\tvalid_0's l2: 0.284033\n",
      "[400]\tvalid_0's l2: 0.283849\n",
      "[450]\tvalid_0's l2: 0.28372\n",
      "[500]\tvalid_0's l2: 0.283577\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's l2: 0.283568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 38587.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 61 done.\n",
      "\n",
      "Processing Chunk 62...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.151928\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.57898\n",
      "[100]\tvalid_0's l2: 0.567326\n",
      "[150]\tvalid_0's l2: 0.564354\n",
      "[200]\tvalid_0's l2: 0.563198\n",
      "[250]\tvalid_0's l2: 0.562434\n",
      "[300]\tvalid_0's l2: 0.562067\n",
      "[350]\tvalid_0's l2: 0.561779\n",
      "[400]\tvalid_0's l2: 0.561577\n",
      "[450]\tvalid_0's l2: 0.561414\n",
      "[500]\tvalid_0's l2: 0.561317\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[491]\tvalid_0's l2: 0.561307\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.151928\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.311435\n",
      "[100]\tvalid_0's l2: 0.293456\n",
      "[150]\tvalid_0's l2: 0.290331\n",
      "[200]\tvalid_0's l2: 0.289316\n",
      "[250]\tvalid_0's l2: 0.288761\n",
      "[300]\tvalid_0's l2: 0.288397\n",
      "[350]\tvalid_0's l2: 0.288129\n",
      "[400]\tvalid_0's l2: 0.287859\n",
      "[450]\tvalid_0's l2: 0.287658\n",
      "[500]\tvalid_0's l2: 0.287536\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.287536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39130.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 62 done.\n",
      "\n",
      "Processing Chunk 63...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.150127\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.581039\n",
      "[100]\tvalid_0's l2: 0.56876\n",
      "[150]\tvalid_0's l2: 0.565833\n",
      "[200]\tvalid_0's l2: 0.564692\n",
      "[250]\tvalid_0's l2: 0.564053\n",
      "[300]\tvalid_0's l2: 0.563615\n",
      "[350]\tvalid_0's l2: 0.563371\n",
      "[400]\tvalid_0's l2: 0.563026\n",
      "[450]\tvalid_0's l2: 0.562909\n",
      "Early stopping, best iteration is:\n",
      "[465]\tvalid_0's l2: 0.562885\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.150127\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.310863\n",
      "[100]\tvalid_0's l2: 0.292036\n",
      "[150]\tvalid_0's l2: 0.288987\n",
      "[200]\tvalid_0's l2: 0.287884\n",
      "[250]\tvalid_0's l2: 0.287176\n",
      "[300]\tvalid_0's l2: 0.286814\n",
      "[350]\tvalid_0's l2: 0.286496\n",
      "[400]\tvalid_0's l2: 0.286249\n",
      "[450]\tvalid_0's l2: 0.286055\n",
      "[500]\tvalid_0's l2: 0.285946\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.285943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 40508.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 63 done.\n",
      "\n",
      "Processing Chunk 64...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.148087\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.581396\n",
      "[100]\tvalid_0's l2: 0.571156\n",
      "[150]\tvalid_0's l2: 0.569245\n",
      "[200]\tvalid_0's l2: 0.568406\n",
      "[250]\tvalid_0's l2: 0.567707\n",
      "[300]\tvalid_0's l2: 0.567341\n",
      "[350]\tvalid_0's l2: 0.56715\n",
      "[400]\tvalid_0's l2: 0.567023\n",
      "[450]\tvalid_0's l2: 0.566954\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid_0's l2: 0.566934\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.148087\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.31501\n",
      "[100]\tvalid_0's l2: 0.296633\n",
      "[150]\tvalid_0's l2: 0.293446\n",
      "[200]\tvalid_0's l2: 0.292292\n",
      "[250]\tvalid_0's l2: 0.291763\n",
      "[300]\tvalid_0's l2: 0.291264\n",
      "[350]\tvalid_0's l2: 0.291011\n",
      "[400]\tvalid_0's l2: 0.290737\n",
      "[450]\tvalid_0's l2: 0.290568\n",
      "[500]\tvalid_0's l2: 0.290416\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l2: 0.290416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39565.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 64 done.\n",
      "\n",
      "Processing Chunk 65...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.149095\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.585484\n",
      "[100]\tvalid_0's l2: 0.575502\n",
      "[150]\tvalid_0's l2: 0.572994\n",
      "[200]\tvalid_0's l2: 0.57231\n",
      "[250]\tvalid_0's l2: 0.571828\n",
      "[300]\tvalid_0's l2: 0.571492\n",
      "[350]\tvalid_0's l2: 0.571288\n",
      "[400]\tvalid_0's l2: 0.57108\n",
      "[450]\tvalid_0's l2: 0.571001\n",
      "[500]\tvalid_0's l2: 0.570946\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[497]\tvalid_0's l2: 0.570941\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 400000, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.149095\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.313836\n",
      "[100]\tvalid_0's l2: 0.295157\n",
      "[150]\tvalid_0's l2: 0.292222\n",
      "[200]\tvalid_0's l2: 0.291229\n",
      "[250]\tvalid_0's l2: 0.290667\n",
      "[300]\tvalid_0's l2: 0.290305\n",
      "[350]\tvalid_0's l2: 0.290068\n",
      "[400]\tvalid_0's l2: 0.28988\n",
      "[450]\tvalid_0's l2: 0.289684\n",
      "[500]\tvalid_0's l2: 0.289627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l2: 0.289624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 100000/100000 [00:02<00:00, 39434.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 65 done.\n",
      "\n",
      "Processing Chunk 66...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 314009, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.126837\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.585086\n",
      "[100]\tvalid_0's l2: 0.573155\n",
      "[150]\tvalid_0's l2: 0.570195\n",
      "[200]\tvalid_0's l2: 0.568801\n",
      "[250]\tvalid_0's l2: 0.56816\n",
      "[300]\tvalid_0's l2: 0.567616\n",
      "[350]\tvalid_0's l2: 0.567302\n",
      "[400]\tvalid_0's l2: 0.567097\n",
      "[450]\tvalid_0's l2: 0.567031\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's l2: 0.566986\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 314009, number of used features: 10\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 4.126837\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's l2: 0.315006\n",
      "[100]\tvalid_0's l2: 0.296006\n",
      "[150]\tvalid_0's l2: 0.292962\n",
      "[200]\tvalid_0's l2: 0.291838\n",
      "[250]\tvalid_0's l2: 0.291186\n",
      "[300]\tvalid_0's l2: 0.290757\n",
      "[350]\tvalid_0's l2: 0.290461\n",
      "[400]\tvalid_0's l2: 0.290226\n",
      "[450]\tvalid_0's l2: 0.289947\n",
      "[500]\tvalid_0's l2: 0.289789\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.289782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Predicting: 100%|██████████| 78503/78503 [00:02<00:00, 38987.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 66 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize storage for meta-model stacking --- [~12 min]\n",
    "all_pred_svd = []\n",
    "all_pred_sentiment = []\n",
    "all_pred_hybrid = []\n",
    "all_true = []\n",
    "\n",
    "chunk_size = 500_000  # safer for memory\n",
    "\n",
    "for chunk_idx, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "    print(f\"\\nProcessing Chunk {chunk_idx+1}...\")\n",
    "\n",
    "    # --- Merge hotel clusters ---\n",
    "    chunk = chunk.merge(hotel_clusters[['hotel_name_id', 'hotel_cluster']], on='hotel_name_id', how='left')\n",
    "\n",
    "    # --- Fill missing values ---\n",
    "    structured_features = ['sleep quality', 'value', 'rooms', 'service', 'cleanliness', 'location']\n",
    "    chunk[structured_features] = chunk[structured_features].fillna(chunk[structured_features].mean())\n",
    "\n",
    "    # --- Prepare LightGBM Features ---\n",
    "    feature_cols = ['hotel_name_id', 'author_id', 'sentiment_score'] + structured_features + ['hotel_cluster']\n",
    "    X = chunk[feature_cols]\n",
    "    y = chunk['rating']\n",
    "\n",
    "    # --- Prepare SVD Data (separately) ---\n",
    "    svd_df = chunk[['author', 'hotel_id', 'rating']]\n",
    "\n",
    "    # --- Train-Test Split for LightGBM ---\n",
    "    X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- Train-Test Split for SVD ---\n",
    "    svd_train_df, svd_test_df = train_test_split(svd_df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # --- Train Sentiment-Aware LightGBM ---\n",
    "    X_train_sentiment = X_train_full[['hotel_name_id', 'author_id', 'sentiment_score']]\n",
    "    X_test_sentiment = X_test_full[['hotel_name_id', 'author_id', 'sentiment_score']]\n",
    "\n",
    "    model_sentiment = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        random_state=42\n",
    "    )\n",
    "    model_sentiment.fit(\n",
    "        X_train_sentiment, y_train_full,\n",
    "        eval_set=[(X_test_sentiment, y_test_full)],\n",
    "        callbacks=[early_stopping(stopping_rounds=20), log_evaluation(50)]\n",
    "    )\n",
    "\n",
    "    preds_sentiment = model_sentiment.predict(X_test_sentiment)\n",
    "\n",
    "    # --- Train Hybrid LightGBM (sentiment + subratings) ---\n",
    "    model_hybrid = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        random_state=42\n",
    "    )\n",
    "    model_hybrid.fit(\n",
    "        X_train_full, y_train_full,\n",
    "        eval_set=[(X_test_full, y_test_full)],\n",
    "        callbacks=[early_stopping(stopping_rounds=20), log_evaluation(50)]\n",
    "    )\n",
    "\n",
    "    preds_hybrid = model_hybrid.predict(X_test_full)\n",
    "\n",
    "    # --- Train SVD Model ---\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    surprise_data = Dataset.load_from_df(svd_train_df[['author', 'hotel_id', 'rating']], reader)\n",
    "    trainset = surprise_data.build_full_trainset()\n",
    "\n",
    "    model_svd = SVD(n_factors=150, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "    model_svd.fit(trainset)\n",
    "\n",
    "    # --- Predict batch for SVD ---\n",
    "    def svd_predict_batch(model, df_batch):\n",
    "        preds = []\n",
    "        for idx, row in tqdm(df_batch.iterrows(), total=len(df_batch), desc=\"SVD Predicting\"):\n",
    "            preds.append(model.predict(row['author'], row['hotel_id']).est)\n",
    "        return np.array(preds)\n",
    "\n",
    "    preds_svd = svd_predict_batch(model_svd, svd_test_df)\n",
    "\n",
    "    # --- Store predictions ---\n",
    "    all_pred_svd.append(preds_svd)\n",
    "    all_pred_sentiment.append(preds_sentiment)\n",
    "    all_pred_hybrid.append(preds_hybrid)\n",
    "    all_true.append(y_test_full.values)\n",
    "\n",
    "    print(f\"Chunk {chunk_idx+1} done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b106dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stack all predictions together ---\n",
    "pred_svd_all = np.concatenate(all_pred_svd)\n",
    "pred_sentiment_all = np.concatenate(all_pred_sentiment)\n",
    "pred_hybrid_all = np.concatenate(all_pred_hybrid)\n",
    "y_true_all = np.concatenate(all_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046f0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_X = np.vstack([pred_svd_all, pred_sentiment_all, pred_hybrid_all]).T\n",
    "stacked_y = y_true_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d018c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Train-Test Split for Meta-Model ---\n",
    "X_train_stack, X_test_stack, y_train_stack, y_test_stack = train_test_split(stacked_X, stacked_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce682ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Train Meta-Model (Linear Regression) ---\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(X_train_stack, y_train_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6446f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict and Evaluate ---\n",
    "y_pred_stack = meta_model.predict(X_test_stack)\n",
    "\n",
    "rmse = mean_squared_error(y_test_stack, y_pred_stack, squared=False)\n",
    "mae = mean_absolute_error(y_test_stack, y_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6834363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Stacked Ensemble Model Results ===\n",
      "RMSE: 0.5418\n",
      "MAE:  0.3754\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Final Stacked Ensemble Model Results ===\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ac47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final stacked meta-model.\n"
     ]
    }
   ],
   "source": [
    "# --- Save Meta-Model ---\n",
    "joblib.dump(meta_model, os.path.join(model_save_path, 'meta_model.pkl'))\n",
    "\n",
    "print(\"Saved final stacked meta-model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
